# ===============================
# PART 1: SENTIMENT ANALYSIS
# ===============================

# Import libraries
import pandas as pd
from textblob import TextBlob
import matplotlib.pyplot as plt
# Load dataset
# Replace filename with downloaded dataset name
df = pd.read_csv("Reviews.csv")

df.head()
# Sentiment classification function
def get_sentiment(text):
    polarity = TextBlob(str(text)).sentiment.polarity
    if polarity > 0:
        return "Positive"
    elif polarity < 0:
        return "Negative"
    else:
        return "Neutral"
# Apply sentiment analysis
df["Sentiment"] = df["review"].apply(get_sentiment)

df.head()
# Sentiment distribution
sentiment_counts = df["Sentiment"].value_counts()
sentiment_percent = df["Sentiment"].value_counts(normalize=True) * 100

sentiment_summary = pd.DataFrame({
    "Count": sentiment_counts,
    "Percentage": sentiment_percent.round(2)
})

sentiment_summary
# Visualization
plt.figure(figsize=(6,4))
sentiment_counts.plot(kind="bar")
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment")
plt.ylabel("Number of Reviews")
plt.show()

# PART 2: STOCK + SENTIMENT LSTM


import numpy as np
from sklearn.preprocessing import MinMaxScaler
# Load stock prices and news datasets
prices = pd.read_csv("AAPL_stock_prices.csv")
news = pd.read_csv("AAPL_news.csv")

prices["Date"] = pd.to_datetime(prices["Date"])
news["Date"] = pd.to_datetime(news["Date"])
# Apply sentiment analysis on news headlines
news["Sentiment"] = news["Headline"].apply(get_sentiment)

sentiment_map = {"Positive": 1, "Neutral": 0, "Negative": -1}
news["Sentiment_Score"] = news["Sentiment"].map(sentiment_map)

news.head()
# Aggregate daily sentiment
daily_sentiment = news.groupby("Date")["Sentiment_Score"].mean().reset_index()
daily_sentiment.head()
# Merge sentiment with stock prices
data = pd.merge(prices, daily_sentiment, on="Date", how="left")

# Treat missing news days as neutral sentiment
data["Sentiment_Score"].fillna(0, inplace=True)

data.head()
# Feature scaling
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(
    data[["Close", "Sentiment_Score"]]
)
# Create LSTM sequences
def create_sequences(data, time_steps=60):
    X, y = [], []
    for i in range(time_steps, len(data)):
        X.append(data[i-time_steps:i])
        y.append(data[i, 0])  # Closing price
    return np.array(X), np.array(y)

X, y = create_sequences(scaled_data)
# Train-test split
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]
# Build LSTM model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    LSTM(50),
    Dense(1)
])

model.compile(optimizer="adam", loss="mse")
model.summary()
# Train model
model.fit(
    X_train,
    y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.1
)
# Predictions
predictions = model.predict(X_test)
# Visualization: Actual vs Predicted
plt.figure(figsize=(8,5))
plt.plot(y_test, label="Actual Price")
plt.plot(predictions, label="Predicted Price")
plt.title("Actual vs Predicted Stock Prices")
plt.xlabel("Time")
plt.ylabel("Normalized Price")
plt.legend()
plt.show()
# Sentiment vs price visualization
plt.figure(figsize=(8,5))
plt.plot(data["Date"], data["Close"], label="Stock Price")
plt.plot(data["Date"], data["Sentiment_Score"], label="Sentiment Score")
plt.legend()
plt.title("Stock Price vs News Sentiment")
plt.show()



